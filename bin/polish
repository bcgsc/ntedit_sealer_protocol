#!/usr/bin/env python3

import argparse
from distutils.command.build import build
import sys
import os
import subprocess as sp
from os.path import join, dirname, realpath, abspath, isfile, isdir, exists, splitext, basename, getsize
sys.path.append(join(realpath(dirname(__file__)), '../btllib/install/python'))
import btllib
import multiprocessing
from multiprocessing import Pool, Lock, Queue, Manager
import threading
import uuid
import shutil
import base64
import time
import signal
import atexit

SHARED_MEMORY_DIR = '/dev/shm'
RECORD_IDS_FILENAME = 'record_ids'

def get_cli_args():
  parser = argparse.ArgumentParser()
  parser.add_argument('to_polish')
  parser.add_argument('reads')
  parser.add_argument('output')
  parser.add_argument('-K', default='32 28 24 20')
  parser.add_argument('--kmer-threshold', type=int, default=10)
  parser.add_argument('--mx-threshold', type=int, default=23)
  parser.add_argument('-b', '--b1size', default=1, type=int, help="Batch 1 size.")
  parser.add_argument('-B', '--b2size', default=128, type=int, help="Batch 2 size.")
  parser.add_argument('-v', '--verbose', action='store_true')

  args = parser.parse_args()
  args.to_polish = abspath(args.to_polish)
  args.reads = abspath(args.reads)
  args.output = abspath(args.output)

  return args

def get_random_name():
  return base64.urlsafe_b64encode(uuid.uuid4().bytes).rstrip(b'=').replace(b'-', b'').decode('ascii')

def _watch_process(process):
  process.wait()
  if process.returncode != 0:
    print(f"{process.args} failed!")
    os.kill(os.getpid(), signal.SIGTERM)

def watch_process(process):
  threading.Thread(target=_watch_process, args=(process,), daemon=True).start()

def handle_sudden_exit(polishing_workspace, prefix):
  process = sp.Popen([ 'polish-cleanup', polishing_workspace, prefix ])
  watch_process(process)

def build_indexes_and_mappings(reads, to_polish, K, to_polish_index, to_polish_read_mapping, reads_index):
  p = sp.run([ f""" \
    ntedit-sealer \
    reads={reads} \
    seqs={to_polish} \
    K='{K}' \
    {to_polish_index} \
    {to_polish_read_mapping} \
    {reads_index} \
  """ ], shell=True, text=True, capture_output=True, check=True)
  btllib.log_info(p.stdout + p.stderr)

def run_bf_builder(bfs_dir, to_polish, to_polish_index, to_polish_read_mapping, reads, reads_index, kmer_threshold, mx_threshold, input_pipepath):
  process = sp.Popen([
    "build_targeted_bfs",
    to_polish,
    to_polish_index,
    to_polish_read_mapping,
    reads,
    reads_index,
    str(kmer_threshold),
    str(mx_threshold)
  ], cwd=bfs_dir)
  watch_process(process)

  while not exists(input_pipepath): time.sleep(2)
  btllib.log_info("build_targeted_bfs is ready!")

  return process

def get_next_batch_of_contigs(reader, record_ids, output_filepath, batch_size):
  with btllib.SeqWriter(output_filepath) as tmpwriter:
    reader_done = True
    while record := reader.read():
      tmpwriter.write(record.id, record.comment, record.seq)
      record_ids.append(record.id)
      if record.num % batch_size == batch_size - 1:
        reader_done = False
        break
    return reader_done

def make_tmp_dir(workspace, prefix, suffix):
  tmp_dir = join(workspace, f"{prefix}-{suffix}")
  os.mkdir(tmp_dir)
  return tmp_dir

def polish_batch(tmp_dir, input_pipepath, confirm_pipepath, to_polish, batch_idx, record_ids, batch_confirmpipe, bfs_dir, verbose):
  with open(input_pipepath, 'w') as f: print(batch_idx, file=f)
  with open(confirm_pipepath)    as f: f.read()

  os.mkfifo(join(tmp_dir, batch_confirmpipe))

  with open(join(tmp_dir, RECORD_IDS_FILENAME), 'w') as f:
    for id in record_ids:
      print(id, file=f)

  process = sp.Popen([
    "polish-batch",
    to_polish,
    args.K,
    str(batch_idx),
    batch_confirmpipe,
    bfs_dir
  ] + ([ '--verbose' ] if verbose else []), cwd=tmp_dir)
  watch_process(process)

def wait_on_batch(batch_confirm_pipepath):
  with open(batch_confirm_pipepath) as f: f.read()

def write_batch_results(tmp_dir, to_polish, writer):
  seqs_path = join(tmp_dir, f"{splitext(to_polish)[0]}.ntedited.prepd.sealer_scaffold.upper.fa")
  if getsize(seqs_path) > 0:
    with btllib.SeqReader(seqs_path, btllib.SeqReaderFlag.LONG_MODE) as tmpreader:
      for record in tmpreader:
        writer.write(record.id, record.comment, record.seq)

def polish_seqs(reader, writer, to_polish, reads, K, kmer_threshold, mx_threshold, batch1_size, batch2_size, verbose):
  cwd = os.getcwd()

  # Work in shared memory if possible
  if isdir(SHARED_MEMORY_DIR):
    polishing_workspace = SHARED_MEMORY_DIR
  else:
    polishing_workspace = cwd
    btllib.log_warning(f"{SHARED_MEMORY_DIR} not present. Polishing might run slower.")

  prefix = get_random_name()

  # Where to build the Bloom filters
  bfs_dir = make_tmp_dir(polishing_workspace, prefix, "targeted_bfs")

  # Pipes for communicating with the process building the Bloom filters
  input_pipepath = join(bfs_dir, "targeted_input")
  confirm_pipepath = join(bfs_dir, "targeted_confirm")

  # Bloom filter names
  bfs = ""
  for k in K.split():
    bfs += join(bfs_dir, f"targeted_k{k}.bf") + " "

  # Temporary name for the contig(s) to polish
  contig_tmppath = "contig.tmp.fa"

  # Indexes and read mapping filenames
  to_polish_index = f"{splitext(basename(to_polish))[0]}.index"
  to_polish_read_mapping = f"{splitext(basename(to_polish))[0]}.read_mapping.tsv"
  reads_index = f"{splitext(basename(reads))[0]}.index"

  # The pipe to communicate with the processes of level two batching
  batch2_confirmpipe = "confirmpipe"

  batch2_paths = []
  handle_sudden_exit(polishing_workspace, prefix)

  build_indexes_and_mappings(reads, to_polish, K, to_polish_index, to_polish_read_mapping, reads_index)

  build_targeted_bfs_process = run_bf_builder(bfs_dir, to_polish, join(cwd, to_polish_index), join(cwd, to_polish_read_mapping), reads, join(cwd, reads_index), kmer_threshold, mx_threshold, input_pipepath)

  btllib.log_info("Polishing batches...")
  reader_done = False
  while not reader_done:
    batch2_paths.clear()

    for batch2_idx in range(batch2_size):
      if reader_done: break

      record_ids = []

      tmp_dir = make_tmp_dir(polishing_workspace, prefix, batch2_idx)
      batch2_paths.append(tmp_dir)

      reader_done = get_next_batch_of_contigs(reader, record_ids, join(tmp_dir, contig_tmppath), batch1_size)

      if len(record_ids) > 0:
        polish_batch(tmp_dir, input_pipepath, confirm_pipepath, contig_tmppath, batch2_idx, record_ids, batch2_confirmpipe, bfs_dir, verbose)
      else:
        shutil.rmtree(tmp_dir, ignore_errors=True)
        batch2_paths.pop()

    for tmp_dir in batch2_paths:
      wait_on_batch(join(tmp_dir, batch2_confirmpipe))
      write_batch_results(tmp_dir, contig_tmppath, writer)
      shutil.rmtree(tmp_dir, ignore_errors=True)

  btllib.log_info("Done polishing batches, ending helper process...")
  with open(input_pipepath, 'w') as f: print("x", file=f)
  build_targeted_bfs_process.wait()
  shutil.rmtree(bfs_dir, ignore_errors=True)
  btllib.log_info("Polisher done")

if __name__ == "__main__":
  args = get_cli_args()

  with btllib.SeqReader(args.to_polish, btllib.SeqReaderFlag.LONG_MODE) as reader, btllib.SeqWriter(args.output) as writer:
    polish_seqs(reader, writer, args.to_polish, args.reads, args.K, args.kmer_threshold, args.mx_threshold, args.b1size, args.b2size, args.verbose)